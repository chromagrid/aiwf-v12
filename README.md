# AIWF v12 â€” Advanced Intelligent Workflow Framework

AIWF v12 is a modular, **cost-optimized**, **high-quality** workflow framework for [n8n](https://n8n.io/), designed to deliver structured, validated AI-powered answers while minimizing API spend.  
This version focuses on **robustness**, **result quality**, and **performance efficiency**, with **full caching**, **reranking**, **tiered routing**, and **schema validation**.

---

## âœ¨ Key Features

- **Cache-first architecture** â€” instant responses for repeated queries.
- **Tiered routing** â€” dynamically picks cheap/standard/premium models based on complexity and risk.
- **Local rerank & dedupe** â€” cut token usage 25â€“50% without sacrificing relevance.
- **Plan â†’ Solve** pattern â€” smaller prompts, tighter context, better results.
- **Strict schema validation** â€” catches malformed outputs and applies cheap fixups.
- **Finalization & clamping** â€” ensures responses stay within defined limits.
- **Cost controls** â€” daily and per-tier caps to prevent runaway billing.
- **Metrics & bandit feedback** â€” lightweight tracking for continuous improvement.
- **Credential isolation** â€” secrets stored only in n8n Credentials.
- **Environment-configurable** â€” all key parameters set via `.env`.

---

## ğŸ“‚ Repository Structure

```

aiwf-v12/
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ aiwf-main.json                  # Main orchestrator workflow
â”‚   â”œâ”€â”€ aiwf-subflow-cache.json         # Redis GET/SET subflow
â”‚   â”œâ”€â”€ aiwf-subflow-rerank.json        # Local rerank & dedupe subflow
â”‚   â”œâ”€â”€ aiwf-subflow-validate.json      # Schema validation & fixup
â”‚   â”œâ”€â”€ aiwf-subflow-finalize.json      # Clamp & finalize response
â”œâ”€â”€ credentials-stubs/
â”‚   â”œâ”€â”€ openrouter.credentials.json
â”‚   â”œâ”€â”€ perplexity.credentials.json
â”‚   â”œâ”€â”€ redis.credentials.json
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md
â”œâ”€â”€ .env.example
â””â”€â”€ README.md

````

---

## âš™ï¸ Environment Variables

Create a `.env` file from `.env.example` with your values:

```env
# Model configuration
CHEAP_MODEL=llama-3.1-8b-instruct
STD_MODEL=llama-3.1-70b-instruct
PREM_MODEL=gpt-4.1

# API Keys (via n8n Credentials ideally)
OPENROUTER_API_KEY=your_key
PPLX_API_KEY=your_key
REDIS_BASE_URL=https://your-redis-rest-endpoint
REDIS_AUTH_HEADER=Bearer your_redis_token

# Cache settings
CACHE_TTL_SEC=1800
RERANK_TOP=8

# Token budgets
MAX_TOKENS_SHORT=384
MAX_TOKENS_STD=768
MAX_TOKENS_LONG=1024

# Cost controls
PREMIUM_RATE_CAP=0.05
PREMIUM_BLOCK=0
COST_CAP_DAILY_USD=5

# Output limits
MAX_ANSWER_LEN=4000
MAX_CITATIONS=10
````

---

## ğŸ”„ How It Works

1. **Webhook Entry** â€” Main workflow receives request.
2. **Normalize & CacheKey** â€” Prepares data and computes a hash key.
3. **Cache GET** â€” Checks Redis for a hit (returns instantly if found).
4. **Guards** â€” Enforces input length, rate limits, and allowed paths.
5. **Router** â€” Chooses the right tier & model based on heuristics.
6. **Catalog Fetch** â€” Retrieves local or indexed context.
7. **Rerank/Dedupe** â€” Filters and scores context locally.
8. **Plan** â€” Cheap model outlines steps & facts needed.
9. **Solve** â€” Higher-tier model generates answer per schema.
10. **Validate** â€” Ensures schema compliance; cheap fixup if needed.
11. **Finalize** â€” Clamps content, sets cache, returns structured JSON.

---

## ğŸš€ Installation

1. **Clone the repo** or download as ZIP.
2. **Import workflows** into n8n **inactive**:

   * `aiwf-main.json`
   * `aiwf-subflow-cache.json`
   * `aiwf-subflow-rerank.json`
   * `aiwf-subflow-validate.json`
   * `aiwf-subflow-finalize.json`
3. **Create n8n Credentials** for:

   * OpenRouter
   * Redis REST
   * (Optional) Perplexity
4. **Update `.env`** with your configuration.
5. **Wire Execute Workflow nodes** in Main to your subflow IDs.
6. Activate **Main** and test.

---

## ğŸ§ª Testing

* Run with sample queries to confirm:

  * Cache hits are instant
  * Correct model tiers are chosen
  * Schema validation passes
* Use `DEBUG=1` in `.env` to enable verbose logs.

---

## ğŸ“Š Observability

* Metrics subflow records:

```json
{
  "ts": 1730000000000,
  "route": "search",
  "tier": "standard",
  "model": "openrouter/llama-3.1-70b-instruct",
  "cache_hit": false,
  "latency_ms": 1100
}
```

* Logs stored in Redis for short-term analysis.

---

## ğŸ’° Cost Optimization

* **Cache-first**: no API calls on repeated queries.
* **Local rerank**: reduces token count for context.
* **Tiered routing**: avoids using expensive models unnecessarily.
* **Daily caps**: stops premium overuse.
* **Adaptive context**: dynamically shortens inputs.

---

## ğŸ” Security

* All API keys are stored as **n8n Credentials** or `.env` variables.
* No secrets in workflow JSON.
* Optional allow-lists for paths/locales.

---

## ğŸ“Œ Recommendations

* Keep `CACHE_TTL_SEC` high for repeated queries.
* Set realistic `COST_CAP_DAILY_USD`.
* Enable Perplexity retrieval only when needed.
* Use `PREMIUM_BLOCK=1` if premium costs are not allowed.

---

## ğŸ› ï¸ Extending AIWF

* Add compliance gates before Router.
* Plug external retrieval services into Rerank subflow.
* Swap models by changing `.env` only.
* Integrate analytics pipelines for metrics.

---

## ğŸ“„ License

MIT License â€” free to use, modify, and distribute.

---

## ğŸ¤ Contributing

1. Fork repo
2. Create a branch (`feature/my-change`)
3. Commit changes
4. Push and open a PR
